{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2632,
     "status": "ok",
     "timestamp": 1584750130912,
     "user": {
      "displayName": "Karthik Bodapati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRtDXeyLxAZZDIxDocBBbr7SK7vsuoztgb52mLwQ=s64",
      "userId": "16344061707883524589"
     },
     "user_tz": 240
    },
    "id": "xHr3djEQrVoj",
    "outputId": "225d2d65-285d-4019-f4f4-9b68ebddc7ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn import svm\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PAQNwRKMwZyI"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = (X_train/255)\n",
    "X_test = (X_test/255)\n",
    "X_train = X_train.reshape(60000,784)\n",
    "X_test = X_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2151439,
     "status": "ok",
     "timestamp": 1584752377965,
     "user": {
      "displayName": "Karthik Bodapati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRtDXeyLxAZZDIxDocBBbr7SK7vsuoztgb52mLwQ=s64",
      "userId": "16344061707883524589"
     },
     "user_tz": 240
    },
    "id": "R0iLyz6T15-Y",
    "outputId": "4ab15f50-ffb5-4940-a452-95cbafd6cfdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185\n",
      "0.9183\n",
      "0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9172\n",
      "0.9171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "c_list = [0.8, 0.9, 1, 5, 10]\n",
    "best_score = 0\n",
    "score_list = list()\n",
    "\n",
    "\n",
    "for c in c_list:\n",
    "    model = svm.LinearSVC(C=c, max_iter = 10000)\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_test,y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "    score_list.append(score)\n",
    "    print(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Evf7g3cm4HQs"
   },
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1584752845562,
     "user": {
      "displayName": "Karthik Bodapati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRtDXeyLxAZZDIxDocBBbr7SK7vsuoztgb52mLwQ=s64",
      "userId": "16344061707883524589"
     },
     "user_tz": 240
    },
    "id": "LfxRopDYMiOE",
    "outputId": "0f8da6fb-6d61-4804-f90b-3ebf9b7e0fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score when C =  0.8 \tis  0.9185\n",
      "Score when C =  0.9 \tis  0.9183\n",
      "Score when C =  1 \tis  0.9183\n",
      "Score when C =  5 \tis  0.9172\n",
      "Score when C =  10 \tis  0.9171\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    print (\"Score when C = \", c_list[i],\"\\tis \" , score_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1191,
     "status": "ok",
     "timestamp": 1584753092248,
     "user": {
      "displayName": "Karthik Bodapati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjRtDXeyLxAZZDIxDocBBbr7SK7vsuoztgb52mLwQ=s64",
      "userId": "16344061707883524589"
     },
     "user_tz": 240
    },
    "id": "vfJOCCxVoagK",
    "outputId": "0a5a4df9-361f-42eb-fd01-ccf5804c3513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY is  0.9185\n"
     ]
    }
   ],
   "source": [
    "Accuracy = best_model.score(X_test,y_test)\n",
    "print (\"ACCURACY is \", Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RgzYexnqpU0e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cfdtt1KeMjt4"
   },
   "source": [
    "## Question 2 - Identify the Lagrange dual problem of the following primal problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWBbZXyqNGG3"
   },
   "source": [
    "### Derivation for Dual optimization \n",
    "\n",
    "Data = $(x_1,y_1), (x_2,y_2),.......(x_n,y_n)$ <br>\n",
    "Goal - Need to Minimize this function $$f(w,\\xi) = w^Tw + C\\sum_{i=1}^{n} \\xi_i$$\n",
    " with respect to these constraints $$ y_iw^Tx_i \\geqslant 1-\\xi_i \\> and \\> \\> \\xi\\geqslant 0$$\n",
    "\n",
    "Lagrangian - $$L(w,\\xi,\\lambda,\\alpha) = w^Tw + C\\sum_{i=1}^{n} \\xi_i - \\sum_{i=1}^{n} \\lambda_i (y_iw^Tx_i - 1 + \\xi_i) - \\sum_{i=1}^{n} \\alpha_i \\xi_i$$\n",
    "\n",
    "from Karush Khun Tucker conditions \n",
    "<br>\n",
    "<br>\n",
    "Condition 1\n",
    "$$\\>\\> \\frac{\\partial L }{\\partial w} = 0$$\n",
    "$$ \\frac{\\partial}{\\partial w} (w^Tw + C\\sum_{i=1}^{n} \\xi_i - \\sum_{i=1}^{n} \\lambda_i (y_iw^Tx_i - 1 + \\xi_i) - \\sum_{i=1}^{n} \\alpha_i \\xi_i)$$\n",
    "\n",
    "$$ \\implies 2w - \\sum_{i=0}^{n}\\lambda_iy_ix_i = 0 $$\n",
    "$$ \\boxed { \\therefore w = \\frac{1}{2} \\sum_{i=0}^{n} \\lambda_iy_ix_i } $$\n",
    "<!-- $$2.\\>\\> \\frac{\\partial L}{\\partial \\xi_i} = 0$$ -->\n",
    "\n",
    "<br>\n",
    "Condition 2\n",
    "$$ \\>\\> \\frac{\\partial L }{\\partial \\xi_i} = 0$$\n",
    "$$ \\frac{\\partial}{\\partial \\xi_i} (w^Tw + C\\sum_{i=1}^{n} \\xi_i - \\sum_{i=1}^{n} \\lambda_i (y_iw^Tx_i - 1 + \\xi_i) - \\sum_{i=1}^{n} \\alpha_i \\xi_i)$$\n",
    "$$ \\implies C - \\lambda - \\alpha = 0$$\n",
    "$$ \\boxed{ \\therefore C = \\lambda + \\alpha }$$\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now Substituting these equations in Lagrangian\n",
    "<br>\n",
    "$$L(w,\\xi,\\lambda,\\alpha) = \\frac{1}{4} \\sum_{i=0}^{n} \\lambda_iy_ix_i^T \\sum_{j=0}^{n} \\lambda_jy_jx_j  + \\sum_{i=1}^{n} (\\lambda_i + \\alpha_i) \\xi_i - \\sum_{i=1}^{n} \\lambda_i y_i(\\frac{1}{2} \\sum_{j=0}^{n} \\lambda_jy_jx_j^T)x_i - 1 + \\xi_i) - \\sum_{i=1}^{n} \\alpha_i \\xi_i$$\n",
    "\n",
    "\n",
    "$$L(w,\\xi,\\lambda,\\alpha) = \\frac{1}{4} \\sum_{i=0}^{n}\\sum_{j=0}^{n} \\lambda_i \\lambda_j y_iy_j x_i^Tx_j + \\sum_{i=1}^{n} \\lambda_i \\xi_i +\\sum_{i=1}^{n} \\alpha_i \\xi_i -\n",
    "\\frac{1}{2}\\sum_{i=1}^{n}\\sum_{j=0}^{n} \\lambda_i\\lambda_j y_iy_jx_i^Tx_j - \\sum_{i=1}^{n} \\lambda_i \\xi_i + \\sum_{i=1}^{n} \\lambda_i- \\sum_{i=1}^{n} \\alpha_i \\xi_i$$\n",
    "\n",
    "Simplyfing this we get\n",
    "\n",
    "$$\\boxed{ L(w,\\xi,\\lambda,\\alpha)_{min(w,\\xi)} = \\frac{-1}{2}\\sum_{i=1}^{n}\\sum_{j=0}^{n} \\lambda_i\\lambda_j y_iy_jx_i^Tx_j +  \\sum_{i=1}^{n} \\lambda_i} $$\n",
    "\n",
    "\n",
    "\n",
    "Dual Optimization\n",
    "\n",
    "$$ Max_{\\lambda, \\alpha}(\\frac{-1}{2}\\sum_{i=1}^{n}\\sum_{j=0}^{n} \\lambda_i\\lambda_j y_iy_jx_i^Tx_j +  \\sum_{i=1}^{n} \\lambda_i)$$\n",
    "\n",
    "Note - $ \\lambda \\geqslant 0 \\>\\> and \\> \\> \\lambda \\leqslant C $\n",
    "$ since \\>\\>\\> C = \\lambda + \\alpha $\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Afm1pnoev-Z"
   },
   "source": [
    "### Point out what is the \"margin\" in both the primal formulation and the dual formulation\n",
    "\n",
    "In primal problem Total margin $\\frac{1}{||w||} + \\frac{1}{||w||}$ <br>\n",
    "In dual problem <br>\n",
    "$w = \\frac{1}{2} \\sum_{i=0}^{n} \\lambda_iy_ix_i$\n",
    "\n",
    "$$\\boxed {\\therefore Margin = \\frac{2}{\\sum_{i=0}^{n} \\lambda_iy_ix_i} + \\frac{2}{\\sum_{i=0}^{n} \\lambda_iy_ix_i} } $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sPZ2M1yQexR5"
   },
   "source": [
    "### What are the benefits of maximizing the margin\n",
    "\n",
    "We can use $ C $ as a trade off between classification error and aximum margin. If C is small, it doesnt penalizes classification error, so margin will be more, How ever if C is large, it penalizes classfication error more , so margins will be smaller. <br>\n",
    "\n",
    "Using Large Margin generalizes data better than small margins. So, overfitting problem here is minimized\n",
    "\n",
    "\n",
    "### Point out the benefit of solving the dual problem instead of the primal problem\n",
    "\n",
    "The main advantages in using dual optimization instead of primal optimization is In dual problem we use inner product of input feature vectors, So we can use kernel trick and without increasing complexity we can project data into higher dimentions and make in linearly seperable \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jDeKpxKakDfW"
   },
   "source": [
    "## Formulate the primal problem and derive the dual problem if there are multiple classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LD3rm4e1ktmq"
   },
   "source": [
    "Derivation doesnt change much from two class SVM <br>\n",
    "We can extend the idea of Two class to Multiclass by training one to all classes <br><br>\n",
    "\n",
    "\n",
    "```\n",
    "for i in range(0,dimentions)\n",
    "    Label = +1 (if class = ith class\n",
    "    Label = -1 (other wise)\n",
    "    Train SVM  \n",
    "When Prediction take argmax(w^Tx + b)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONcQaCzdqb29"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMduuwR1DbbjvTiAZNvdKjK",
   "name": "PR_Assignment 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
